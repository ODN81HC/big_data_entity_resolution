{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938c1e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import operator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bec613",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dataset_path = 'movies_metadata.csv'\n",
    "cols = ['genres', 'imdb_id', 'title', 'production_companies', 'production_countries']\n",
    "\n",
    "# Read movies_metadata.csv & chosen columns & drop NA\n",
    "movies_df = pd.read_csv(movies_dataset_path, usecols=cols).dropna()\n",
    "\n",
    "# Drop rows whose 'genres' == [] or 'production_companies' == [] or 'production_countries' == []\n",
    "movies_df = movies_df[(movies_df['genres'] != '[]')  & \\\n",
    "                        (movies_df['production_companies'] != '[]') & \\\n",
    "                        (movies_df['production_countries'] != '[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e752b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 200 random rows\n",
    "random_movies_df = movies_df.sample(n=200).reset_index(drop=True)\n",
    "\n",
    "# Make 2 seperate KBs from random_movies_df\n",
    "kb1 = random_movies_df.sample(n=120)\n",
    "kb2 = random_movies_df.sample(n=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9b8c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'id': 878, 'name': 'Science Fiction'}, {'id'...</td>\n",
       "      <td>tt0070122</td>\n",
       "      <td>[{'name': 'Toho Film (Eiga) Co. Ltd.', 'id': 6...</td>\n",
       "      <td>[{'iso_3166_1': 'JP', 'name': 'Japan'}]</td>\n",
       "      <td>Godzilla vs. Megalon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>tt1850419</td>\n",
       "      <td>[{'name': 'Mij Film Co.', 'id': 2440}, {'name'...</td>\n",
       "      <td>[{'iso_3166_1': 'TR', 'name': 'Turkey'}, {'iso...</td>\n",
       "      <td>Rhino Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'id': 878, 'name': 'Science Fiction'}, {'id'...</td>\n",
       "      <td>tt1817771</td>\n",
       "      <td>[{'name': 'Columbia Pictures', 'id': 5}, {'nam...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>Freaks of Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 28, '...</td>\n",
       "      <td>tt0080166</td>\n",
       "      <td>[{'name': 'Golden Harvest Company Ltd.', 'id':...</td>\n",
       "      <td>[{'iso_3166_1': 'HK', 'name': 'Hong Kong'}]</td>\n",
       "      <td>Knockabout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>tt1326238</td>\n",
       "      <td>[{'name': 'Virtual Audiovisuais', 'id': 16406}]</td>\n",
       "      <td>[{'iso_3166_1': 'PT', 'name': 'Portugal'}, {'i...</td>\n",
       "      <td>Backlight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres    imdb_id  \\\n",
       "0  [{'id': 878, 'name': 'Science Fiction'}, {'id'...  tt0070122   \n",
       "1                      [{'id': 18, 'name': 'Drama'}]  tt1850419   \n",
       "2  [{'id': 878, 'name': 'Science Fiction'}, {'id'...  tt1817771   \n",
       "3  [{'id': 12, 'name': 'Adventure'}, {'id': 28, '...  tt0080166   \n",
       "4  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...  tt1326238   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{'name': 'Toho Film (Eiga) Co. Ltd.', 'id': 6...   \n",
       "1  [{'name': 'Mij Film Co.', 'id': 2440}, {'name'...   \n",
       "2  [{'name': 'Columbia Pictures', 'id': 5}, {'nam...   \n",
       "3  [{'name': 'Golden Harvest Company Ltd.', 'id':...   \n",
       "4    [{'name': 'Virtual Audiovisuais', 'id': 16406}]   \n",
       "\n",
       "                                production_countries                 title  \n",
       "0            [{'iso_3166_1': 'JP', 'name': 'Japan'}]  Godzilla vs. Megalon  \n",
       "1  [{'iso_3166_1': 'TR', 'name': 'Turkey'}, {'iso...          Rhino Season  \n",
       "2  [{'iso_3166_1': 'US', 'name': 'United States o...      Freaks of Nature  \n",
       "3        [{'iso_3166_1': 'HK', 'name': 'Hong Kong'}]            Knockabout  \n",
       "4  [{'iso_3166_1': 'PT', 'name': 'Portugal'}, {'i...             Backlight  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06060327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 35, '...</td>\n",
       "      <td>tt0060125</td>\n",
       "      <td>[{'name': 'Fair Film', 'id': 1399}, {'name': '...</td>\n",
       "      <td>[{'iso_3166_1': 'ES', 'name': 'Spain'}, {'iso_...</td>\n",
       "      <td>For Love and Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...</td>\n",
       "      <td>tt0273300</td>\n",
       "      <td>[{'name': 'Eureka Pictures', 'id': 1002}, {'na...</td>\n",
       "      <td>[{'iso_3166_1': 'GB', 'name': 'United Kingdom'...</td>\n",
       "      <td>Jump Tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[{'id': 10770, 'name': 'TV Movie'}, {'id': 18,...</td>\n",
       "      <td>tt3320502</td>\n",
       "      <td>[{'name': 'Lighthouse Pictures', 'id': 6345}, ...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>Let It Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>tt0381681</td>\n",
       "      <td>[{'name': 'Castle Rock Entertainment', 'id': 9...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>Before Sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 27, 'name...</td>\n",
       "      <td>tt0021884</td>\n",
       "      <td>[{'name': 'Universal Pictures', 'id': 33}]</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>Frankenstein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                genres    imdb_id  \\\n",
       "29   [{'id': 12, 'name': 'Adventure'}, {'id': 35, '...  tt0060125   \n",
       "149  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...  tt0273300   \n",
       "36   [{'id': 10770, 'name': 'TV Movie'}, {'id': 18,...  tt3320502   \n",
       "135  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...  tt0381681   \n",
       "87   [{'id': 18, 'name': 'Drama'}, {'id': 27, 'name...  tt0021884   \n",
       "\n",
       "                                  production_companies  \\\n",
       "29   [{'name': 'Fair Film', 'id': 1399}, {'name': '...   \n",
       "149  [{'name': 'Eureka Pictures', 'id': 1002}, {'na...   \n",
       "36   [{'name': 'Lighthouse Pictures', 'id': 6345}, ...   \n",
       "135  [{'name': 'Castle Rock Entertainment', 'id': 9...   \n",
       "87          [{'name': 'Universal Pictures', 'id': 33}]   \n",
       "\n",
       "                                  production_countries              title  \n",
       "29   [{'iso_3166_1': 'ES', 'name': 'Spain'}, {'iso_...  For Love and Gold  \n",
       "149  [{'iso_3166_1': 'GB', 'name': 'United Kingdom'...      Jump Tomorrow  \n",
       "36   [{'iso_3166_1': 'US', 'name': 'United States o...        Let It Snow  \n",
       "135  [{'iso_3166_1': 'US', 'name': 'United States o...      Before Sunset  \n",
       "87   [{'iso_3166_1': 'US', 'name': 'United States o...       Frankenstein  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f257929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...</td>\n",
       "      <td>tt0097584</td>\n",
       "      <td>[{'name': 'Mosfilm', 'id': 5120}]</td>\n",
       "      <td>[{'iso_3166_1': 'RU', 'name': 'Russia'}, {'iso...</td>\n",
       "      <td>Intergirl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[{'id': 99, 'name': 'Documentary'}]</td>\n",
       "      <td>tt6146460</td>\n",
       "      <td>[{'name': 'Radical Media', 'id': 11152}]</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>Hamilton's America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 36, 'name...</td>\n",
       "      <td>tt0082095</td>\n",
       "      <td>[{'name': 'Österreichischer Rundfunk (ORF)', '...</td>\n",
       "      <td>[{'iso_3166_1': 'AT', 'name': 'Austria'}, {'is...</td>\n",
       "      <td>The Boat Is Full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 10751, '...</td>\n",
       "      <td>tt0111470</td>\n",
       "      <td>[{'name': 'Overseas FilmGroup', 'id': 888}, {'...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>Trading Mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>[{'id': 80, 'name': 'Crime'}, {'id': 18, 'name...</td>\n",
       "      <td>tt0061418</td>\n",
       "      <td>[{'name': 'Tatira-Hiller Productions', 'id': 2...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>Bonnie and Clyde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                genres    imdb_id  \\\n",
       "115  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'n...  tt0097584   \n",
       "59                 [{'id': 99, 'name': 'Documentary'}]  tt6146460   \n",
       "118  [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name...  tt0082095   \n",
       "110  [{'id': 35, 'name': 'Comedy'}, {'id': 10751, '...  tt0111470   \n",
       "147  [{'id': 80, 'name': 'Crime'}, {'id': 18, 'name...  tt0061418   \n",
       "\n",
       "                                  production_companies  \\\n",
       "115                  [{'name': 'Mosfilm', 'id': 5120}]   \n",
       "59            [{'name': 'Radical Media', 'id': 11152}]   \n",
       "118  [{'name': 'Österreichischer Rundfunk (ORF)', '...   \n",
       "110  [{'name': 'Overseas FilmGroup', 'id': 888}, {'...   \n",
       "147  [{'name': 'Tatira-Hiller Productions', 'id': 2...   \n",
       "\n",
       "                                  production_countries               title  \n",
       "115  [{'iso_3166_1': 'RU', 'name': 'Russia'}, {'iso...           Intergirl  \n",
       "59   [{'iso_3166_1': 'US', 'name': 'United States o...  Hamilton's America  \n",
       "118  [{'iso_3166_1': 'AT', 'name': 'Austria'}, {'is...    The Boat Is Full  \n",
       "110  [{'iso_3166_1': 'US', 'name': 'United States o...         Trading Mom  \n",
       "147  [{'iso_3166_1': 'US', 'name': 'United States o...    Bonnie and Clyde  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cba2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Make a string of list of dictionaries into list of names of features.\n",
    "# E.g. 'genres' column output only contains 'Drama, Action, Documentary'\n",
    "def dicts_list_to_str(df: pd.DataFrame, columns_to_modify):\n",
    "    df_clone = df.copy()\n",
    "    for index, row in df_clone.iterrows():\n",
    "        for col in columns_to_modify:\n",
    "            list_of_dicts = eval(row[col])\n",
    "            if col == 'production_countries':\n",
    "                col_elements = [col_dict['iso_3166_1'] for col_dict in list_of_dicts]\n",
    "            else:\n",
    "                col_elements = [col_dict['name'] for col_dict in list_of_dicts]\n",
    "            col_str = ' '.join(col_elements)\n",
    "            # Replace back to the column name\n",
    "            row[col] = col_str\n",
    "    \n",
    "    return df_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581fa774",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_modify = ['genres', 'production_companies', 'production_countries']\n",
    "kb1_modified = dicts_list_to_str(kb1, columns_to_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9fced9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adventure Comedy</td>\n",
       "      <td>tt0060125</td>\n",
       "      <td>Fair Film Cecchi Gori Group</td>\n",
       "      <td>ES FR IT</td>\n",
       "      <td>For Love and Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Drama Comedy Romance</td>\n",
       "      <td>tt0273300</td>\n",
       "      <td>Eureka Pictures Filmfour</td>\n",
       "      <td>GB US</td>\n",
       "      <td>Jump Tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TV Movie Drama Romance Family</td>\n",
       "      <td>tt3320502</td>\n",
       "      <td>Lighthouse Pictures Craig Anderson Productions...</td>\n",
       "      <td>US</td>\n",
       "      <td>Let It Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Drama Romance</td>\n",
       "      <td>tt0381681</td>\n",
       "      <td>Castle Rock Entertainment Detour Film Producti...</td>\n",
       "      <td>US</td>\n",
       "      <td>Before Sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Drama Horror Science Fiction</td>\n",
       "      <td>tt0021884</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>US</td>\n",
       "      <td>Frankenstein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            genres    imdb_id  \\\n",
       "29                Adventure Comedy  tt0060125   \n",
       "149           Drama Comedy Romance  tt0273300   \n",
       "36   TV Movie Drama Romance Family  tt3320502   \n",
       "135                  Drama Romance  tt0381681   \n",
       "87    Drama Horror Science Fiction  tt0021884   \n",
       "\n",
       "                                  production_companies production_countries  \\\n",
       "29                         Fair Film Cecchi Gori Group             ES FR IT   \n",
       "149                           Eureka Pictures Filmfour                GB US   \n",
       "36   Lighthouse Pictures Craig Anderson Productions...                   US   \n",
       "135  Castle Rock Entertainment Detour Film Producti...                   US   \n",
       "87                                  Universal Pictures                   US   \n",
       "\n",
       "                 title  \n",
       "29   For Love and Gold  \n",
       "149      Jump Tomorrow  \n",
       "36         Let It Snow  \n",
       "135      Before Sunset  \n",
       "87        Frankenstein  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb1_modified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0bc297",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb2_modified = dicts_list_to_str(kb2, columns_to_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ea2db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Drama Romance</td>\n",
       "      <td>tt0097584</td>\n",
       "      <td>Mosfilm</td>\n",
       "      <td>RU SE</td>\n",
       "      <td>Intergirl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>tt6146460</td>\n",
       "      <td>Radical Media</td>\n",
       "      <td>US</td>\n",
       "      <td>Hamilton's America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Drama History War</td>\n",
       "      <td>tt0082095</td>\n",
       "      <td>Österreichischer Rundfunk (ORF) Zweites Deutsc...</td>\n",
       "      <td>AT DE CH</td>\n",
       "      <td>The Boat Is Full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Comedy Family</td>\n",
       "      <td>tt0111470</td>\n",
       "      <td>Overseas FilmGroup First Look International Mo...</td>\n",
       "      <td>US</td>\n",
       "      <td>Trading Mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Crime Drama</td>\n",
       "      <td>tt0061418</td>\n",
       "      <td>Tatira-Hiller Productions Warner Brothers/Seve...</td>\n",
       "      <td>US</td>\n",
       "      <td>Bonnie and Clyde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                genres    imdb_id  \\\n",
       "115      Drama Romance  tt0097584   \n",
       "59         Documentary  tt6146460   \n",
       "118  Drama History War  tt0082095   \n",
       "110      Comedy Family  tt0111470   \n",
       "147        Crime Drama  tt0061418   \n",
       "\n",
       "                                  production_companies production_countries  \\\n",
       "115                                            Mosfilm                RU SE   \n",
       "59                                       Radical Media                   US   \n",
       "118  Österreichischer Rundfunk (ORF) Zweites Deutsc...             AT DE CH   \n",
       "110  Overseas FilmGroup First Look International Mo...                   US   \n",
       "147  Tatira-Hiller Productions Warner Brothers/Seve...                   US   \n",
       "\n",
       "                  title  \n",
       "115           Intergirl  \n",
       "59   Hamilton's America  \n",
       "118    The Boat Is Full  \n",
       "110         Trading Mom  \n",
       "147    Bonnie and Clyde  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb2_modified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "542c07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_kb2(df: pd.DataFrame, randomly_removed_cols):\n",
    "    df_clone = df.copy()\n",
    "    for index, row in df_clone.iterrows():\n",
    "        # For 'genres', 'production_countries', if there is only 1 genre, keep it. Otherwise, remove one of them\n",
    "        for col in randomly_removed_cols:\n",
    "            feature_list = row[col].split(' ')\n",
    "            if len(feature_list) > 1:\n",
    "                # Randomly remove 1 of them\n",
    "                random.shuffle(feature_list)\n",
    "                feature_list.pop()\n",
    "                # Merge back as a string\n",
    "                features_str = ' '.join(feature_list)\n",
    "                row[col] = features_str\n",
    "        \n",
    "        \n",
    "        # For 'title', make some changes so it looks like a typo\n",
    "        title_list = row['title'].split(' ')\n",
    "        # Make typo changes only with 'title' has more than 2 words\n",
    "        if len(title_list) > 2:\n",
    "            row['title'] = row['title'].replace('a', '4').replace('i', 'j')\n",
    "    return df_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a1eef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomly_remove_cols = ['genres', 'production_countries']\n",
    "\n",
    "kb2_processed = modified_kb2(kb2_modified, randomly_remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "197f4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify KBs' attributes (column name) so that they are different, and easier for later blocking methods\n",
    "def name_modification(Kb, appended_str:str):\n",
    "    Kb_clone = Kb.copy()\n",
    "    name_modification_dict = {}\n",
    "    for col in Kb_clone.columns:\n",
    "        name_modification_dict[col] = col + appended_str\n",
    "    Kb_clone.rename(name_modification_dict, axis=1, inplace=True)\n",
    "\n",
    "    return Kb_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3a38e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb1_processed = name_modification(kb1_modified, '_kb1')\n",
    "kb2_processed_2 = name_modification(kb2_processed, '_kb2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ecd20",
   "metadata": {},
   "source": [
    "### Final KBs\n",
    "\n",
    "kb1_processed & kb2_processed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b3153b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_kb1</th>\n",
       "      <th>imdb_id_kb1</th>\n",
       "      <th>production_companies_kb1</th>\n",
       "      <th>production_countries_kb1</th>\n",
       "      <th>title_kb1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adventure Comedy</td>\n",
       "      <td>tt0060125</td>\n",
       "      <td>Fair Film Cecchi Gori Group</td>\n",
       "      <td>ES FR IT</td>\n",
       "      <td>For Love and Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Drama Comedy Romance</td>\n",
       "      <td>tt0273300</td>\n",
       "      <td>Eureka Pictures Filmfour</td>\n",
       "      <td>GB US</td>\n",
       "      <td>Jump Tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TV Movie Drama Romance Family</td>\n",
       "      <td>tt3320502</td>\n",
       "      <td>Lighthouse Pictures Craig Anderson Productions...</td>\n",
       "      <td>US</td>\n",
       "      <td>Let It Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Drama Romance</td>\n",
       "      <td>tt0381681</td>\n",
       "      <td>Castle Rock Entertainment Detour Film Producti...</td>\n",
       "      <td>US</td>\n",
       "      <td>Before Sunset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Drama Horror Science Fiction</td>\n",
       "      <td>tt0021884</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>US</td>\n",
       "      <td>Frankenstein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        genres_kb1 imdb_id_kb1  \\\n",
       "29                Adventure Comedy   tt0060125   \n",
       "149           Drama Comedy Romance   tt0273300   \n",
       "36   TV Movie Drama Romance Family   tt3320502   \n",
       "135                  Drama Romance   tt0381681   \n",
       "87    Drama Horror Science Fiction   tt0021884   \n",
       "\n",
       "                              production_companies_kb1  \\\n",
       "29                         Fair Film Cecchi Gori Group   \n",
       "149                           Eureka Pictures Filmfour   \n",
       "36   Lighthouse Pictures Craig Anderson Productions...   \n",
       "135  Castle Rock Entertainment Detour Film Producti...   \n",
       "87                                  Universal Pictures   \n",
       "\n",
       "    production_countries_kb1          title_kb1  \n",
       "29                  ES FR IT  For Love and Gold  \n",
       "149                    GB US      Jump Tomorrow  \n",
       "36                        US        Let It Snow  \n",
       "135                       US      Before Sunset  \n",
       "87                        US       Frankenstein  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final KBs\n",
    "kb1_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a58c132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres_kb2</th>\n",
       "      <th>imdb_id_kb2</th>\n",
       "      <th>production_companies_kb2</th>\n",
       "      <th>production_countries_kb2</th>\n",
       "      <th>title_kb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Romance</td>\n",
       "      <td>tt0097584</td>\n",
       "      <td>Mosfilm</td>\n",
       "      <td>RU</td>\n",
       "      <td>Intergirl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>tt6146460</td>\n",
       "      <td>Radical Media</td>\n",
       "      <td>US</td>\n",
       "      <td>Hamilton's America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Drama History</td>\n",
       "      <td>tt0082095</td>\n",
       "      <td>Österreichischer Rundfunk (ORF) Zweites Deutsc...</td>\n",
       "      <td>CH AT</td>\n",
       "      <td>The Bo4t Is Full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>tt0111470</td>\n",
       "      <td>Overseas FilmGroup First Look International Mo...</td>\n",
       "      <td>US</td>\n",
       "      <td>Trading Mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Drama</td>\n",
       "      <td>tt0061418</td>\n",
       "      <td>Tatira-Hiller Productions Warner Brothers/Seve...</td>\n",
       "      <td>US</td>\n",
       "      <td>Bonnje 4nd Clyde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        genres_kb2 imdb_id_kb2  \\\n",
       "115        Romance   tt0097584   \n",
       "59     Documentary   tt6146460   \n",
       "118  Drama History   tt0082095   \n",
       "110         Comedy   tt0111470   \n",
       "147          Drama   tt0061418   \n",
       "\n",
       "                              production_companies_kb2  \\\n",
       "115                                            Mosfilm   \n",
       "59                                       Radical Media   \n",
       "118  Österreichischer Rundfunk (ORF) Zweites Deutsc...   \n",
       "110  Overseas FilmGroup First Look International Mo...   \n",
       "147  Tatira-Hiller Productions Warner Brothers/Seve...   \n",
       "\n",
       "    production_countries_kb2           title_kb2  \n",
       "115                       RU           Intergirl  \n",
       "59                        US  Hamilton's America  \n",
       "118                    CH AT    The Bo4t Is Full  \n",
       "110                       US         Trading Mom  \n",
       "147                       US    Bonnje 4nd Clyde  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb2_processed_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43954ae",
   "metadata": {},
   "source": [
    "# Token blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae98c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db1 = kb1_processed.copy()\n",
    "test_db2 = kb2_processed_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3aab1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_extraction(Kb, appended_str):\n",
    "    dict_kb = {}\n",
    "    \n",
    "    for idxRow, row_ in Kb.iterrows():\n",
    "        for idxCol, col_ in row_.iteritems():\n",
    "            col_tokens = col_.split(' ')\n",
    "            \n",
    "            for token in col_tokens:\n",
    "                if token in dict_kb.keys():\n",
    "                    dict_kb[token].append(str(idxRow) + appended_str)\n",
    "                else:\n",
    "                    dict_kb[token] = [str(idxRow) + appended_str]\n",
    "                    \n",
    "    # Make values in each key appears once\n",
    "    for key, value in dict_kb.items():\n",
    "        dict_kb[key] = list(set(value))\n",
    "        \n",
    "    return dict_kb\n",
    "\n",
    "def token_blocking(Kb1, Kb2):\n",
    "    \n",
    "    dict_db1 = tokens_extraction(test_db1, '_kb1')\n",
    "    dict_db2 = tokens_extraction(test_db2, '_kb2')\n",
    "    \n",
    "    blocks = {}\n",
    "\n",
    "    for key in dict_db1.keys():\n",
    "        if key in dict_db2.keys():\n",
    "            rows_kb1 = dict_db1[key][:]\n",
    "            rows_kb1.extend(dict_db2[key])\n",
    "            blocks[key] = rows_kb1\n",
    "            \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fd40793",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_blocks = token_blocking(test_db1, test_db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9b6e3",
   "metadata": {},
   "source": [
    "# Attribute Clustering Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87b45dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribute_tokens(Kb):\n",
    "    attribute_token = {}\n",
    "    # Loop through all attribute names\n",
    "    for i in list(Kb):\n",
    "        attribute_values = Kb[i].tolist()\n",
    "        tokens_list = []\n",
    "        # Loop each entry (row) in attribute_values\n",
    "        for entry in attribute_values:\n",
    "            tokens = entry.split(' ')\n",
    "            tokens_list.extend(tokens)\n",
    "        # Turn it into a set so that each token appears once\n",
    "        tokens_set = list(set(tokens_list))\n",
    "        attribute_token[i] = tokens_set\n",
    "    \n",
    "    return attribute_token\n",
    "\n",
    "def get_links(ref_token_dict, target_token_dict):\n",
    "    links = []\n",
    "    standalone_attribute = []\n",
    "    for attribute_ref in ref_token_dict.keys():\n",
    "        link_exist = False\n",
    "        # Compare with all attributes name in target_token_dict:\n",
    "        for attribute_target in target_token_dict.keys():\n",
    "            # Mutual tokens\n",
    "            mutual_tokens = set(ref_token_dict[attribute_ref]).intersection(target_token_dict[attribute_target])\n",
    "            # Total tokens\n",
    "            tokens_ref = ref_token_dict[attribute_ref][:]\n",
    "            tokens_ref.extend(target_token_dict[attribute_target])\n",
    "            total_tokens = set(tokens_ref)\n",
    "            # Add link if the Jaccard similarity score is > 0\n",
    "            jaccard_similarity_score = len(mutual_tokens)/len(total_tokens)\n",
    "            if jaccard_similarity_score > 0:\n",
    "                links.append([attribute_ref, attribute_target])\n",
    "                link_exist = True\n",
    "\n",
    "        # This is when no link is added, so that the attribute_ref key does not exist yet\n",
    "        if not link_exist:\n",
    "            standalone_attribute.append(attribute_ref)\n",
    "    \n",
    "    return links, standalone_attribute\n",
    "\n",
    "def transitive_closure(edges):\n",
    "    clusters = []\n",
    "    for edge in edges:\n",
    "        u = edge[0]\n",
    "        v = edge[1]\n",
    "        if len(clusters) == 0:\n",
    "            clusters.append({u,v}) \n",
    "        else:\n",
    "            if any(not {u,v}.isdisjoint(c) for c in clusters):\n",
    "                for c in clusters:\n",
    "                    if (u in c) or (v in c):\n",
    "                        c.add(u)\n",
    "                        c.add(v)          \n",
    "            else:\n",
    "                clusters.append({u,v})\n",
    "    return clusters\n",
    "\n",
    "def attribute_clustering_blocking(kb1, kb2):\n",
    "    # Get tokens of all attributes name in the Kb\n",
    "    attribute_token_kb1 = get_attribute_tokens(kb1)\n",
    "    attribute_token_kb2 = get_attribute_tokens(kb2)\n",
    "    \n",
    "    # Get links by Jaccard similarity\n",
    "    links_by_kb1, standalone_attributes_1 = get_links(attribute_token_kb1, attribute_token_kb2)\n",
    "    links_by_kb2, standalone_attributes_2 = get_links(attribute_token_kb2, attribute_token_kb1)\n",
    "    \n",
    "    links = links_by_kb1 + links_by_kb2\n",
    "    standalone_attributes = standalone_attributes_1 + standalone_attributes_2\n",
    "    \n",
    "    clusters = transitive_closure(links)\n",
    "\n",
    "    if len(standalone_attributes) != 0:\n",
    "        clusters.append(set(standalone_attributes))\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e67606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = attribute_clustering_blocking(test_db1, test_db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6255a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_name(clusters, idxCol):\n",
    "    for idx, c in enumerate(clusters):\n",
    "        if idxCol in c:\n",
    "            return 'c'+ str(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba020c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db1 = kb1_processed.copy()\n",
    "test_db2 = kb2_processed_2.copy()\n",
    "\n",
    "dict_db1 = {}\n",
    "dict_db2 = {}\n",
    "\n",
    "# Get token of every KBs\n",
    "for (idxRow1, row1), (idxRow2, row2) in zip(test_db1.iterrows(), test_db2.iterrows()):\n",
    "    for (idxCol1, col1), (idxCol2, col2) in zip(row1.iteritems(), row2.iteritems()):\n",
    "        col1_string = col1.split(' ')\n",
    "        col2_string = col2.split(' ')\n",
    "        \n",
    "        # Add into the dictionaries, with key is the word token and the value is the rowIdx\n",
    "        for token in col1_string:\n",
    "            token = get_cluster_name(clusters, idxCol1) + '.' + token\n",
    "            if token in dict_db1.keys():\n",
    "                dict_db1[token].append(str(idxRow1) + '_kb1')\n",
    "            else:\n",
    "                dict_db1[token] = [str(idxRow1) + '_kb1']\n",
    "                \n",
    "        for token in col2_string:\n",
    "            token = get_cluster_name(clusters, idxCol2) + '.' + token\n",
    "            if token in dict_db2.keys():\n",
    "                dict_db2[token].append(str(idxRow2) + '_kb2')\n",
    "            else:\n",
    "                dict_db2[token] = [str(idxRow2) + '_kb2']\n",
    "\n",
    "# Make values in each key appears once\n",
    "for key, values in dict_db1.items():\n",
    "    dict_db1[key] = list(set(values))\n",
    "    \n",
    "for key, values in dict_db2.items():\n",
    "    dict_db2[key] = list(set(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "357f2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocking\n",
    "attribute_blocks = {}\n",
    "\n",
    "for key in dict_db1.keys():\n",
    "    if key in dict_db2.keys():\n",
    "        rows_kb1 = dict_db1[key][:]\n",
    "        rows_kb1.extend(dict_db2[key])\n",
    "        attribute_blocks[key] = rows_kb1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63c41d",
   "metadata": {},
   "source": [
    "## Blocking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7c57f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adventure:['112_kb1', '6_kb1', '94_kb1', '106_kb1', '84_kb1', '132_kb1', '44_kb1', '64_kb1', '50_kb1', '107_kb1', '166_kb1', '123_kb1', '29_kb1', '8_kb1', '166_kb2', '3_kb2', '44_kb2', '112_kb2', '107_kb2', '132_kb2', '8_kb2', '7_kb2']\n",
      "Comedy:['20_kb1', '149_kb1', '16_kb1', '132_kb1', '108_kb1', '190_kb1', '159_kb1', '65_kb1', '128_kb1', '189_kb1', '23_kb1', '17_kb1', '63_kb1', '178_kb1', '116_kb1', '191_kb1', '133_kb1', '95_kb1', '26_kb1', '13_kb1', '101_kb1', '162_kb1', '117_kb1', '148_kb1', '181_kb1', '110_kb1', '123_kb1', '70_kb1', '160_kb1', '29_kb1', '142_kb2', '78_kb2', '17_kb2', '63_kb2', '113_kb2', '133_kb2', '26_kb2', '160_kb2', '179_kb2', '149_kb2', '197_kb2', '86_kb2', '12_kb2', '13_kb2', '171_kb2', '148_kb2', '62_kb2', '49_kb2', '184_kb2', '30_kb2', '189_kb2', '102_kb2', '110_kb2']\n",
      "Film:['108_kb1', '168_kb1', '50_kb1', '130_kb1', '83_kb1', '135_kb1', '190_kb1', '67_kb1', '58_kb1', '42_kb1', '61_kb1', '128_kb1', '23_kb1', '24_kb1', '166_kb1', '29_kb1', '1_kb1', '95_kb1', '118_kb1', '145_kb1', '114_kb1', '46_kb1', '181_kb1', '92_kb1', '137_kb1', '27_kb1', '118_kb2', '92_kb2', '1_kb2', '168_kb2', '24_kb2', '95_kb2', '114_kb2', '125_kb2', '46_kb2', '27_kb2', '138_kb2', '108_kb2', '199_kb2', '83_kb2', '62_kb2', '166_kb2', '151_kb2', '61_kb2', '98_kb2', '58_kb2', '137_kb2']\n",
      "Group:['180_kb1', '29_kb1', '168_kb1', '61_kb1', '61_kb2', '168_kb2', '180_kb2']\n",
      "ES:['9_kb1', '126_kb1', '180_kb1', '29_kb1', '97_kb1', '97_kb2']\n",
      "FR:['75_kb1', '46_kb1', '106_kb1', '126_kb1', '24_kb1', '52_kb1', '139_kb1', '83_kb1', '29_kb1', '136_kb1', '97_kb1', '24_kb2', '30_kb2', '197_kb2', '98_kb2', '46_kb2', '136_kb2', '83_kb2', '97_kb2']\n",
      "IT:['75_kb1', '61_kb1', '121_kb1', '83_kb1', '29_kb1', '136_kb1', '138_kb2', '61_kb2', '121_kb2', '60_kb2', '113_kb2', '136_kb2']\n",
      "For:['29_kb1', '144_kb2']\n",
      "Love:['95_kb1', '29_kb1', '181_kb1', '95_kb2', '113_kb2']\n",
      "and:['191_kb1', '133_kb1', '106_kb1', '108_kb1', '105_kb1', '130_kb1', '93_kb1', '147_kb1', '29_kb1', '93_kb2', '108_kb2']\n"
     ]
    }
   ],
   "source": [
    "for i, block in enumerate(token_blocks):\n",
    "    # Print 10 blocks for example\n",
    "    if i < 10:\n",
    "        print(\"{}:{}\".format(block, token_blocks[block]))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edce8cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0.Adventure:['112_kb1', '6_kb1', '94_kb1', '106_kb1', '84_kb1', '132_kb1', '44_kb1', '64_kb1', '50_kb1', '107_kb1', '166_kb1', '123_kb1', '29_kb1', '8_kb1', '166_kb2', '3_kb2', '44_kb2', '112_kb2', '107_kb2', '132_kb2', '8_kb2', '7_kb2']\n",
      "c0.Comedy:['20_kb1', '149_kb1', '16_kb1', '132_kb1', '108_kb1', '190_kb1', '159_kb1', '65_kb1', '128_kb1', '189_kb1', '23_kb1', '17_kb1', '63_kb1', '178_kb1', '116_kb1', '191_kb1', '133_kb1', '95_kb1', '26_kb1', '13_kb1', '101_kb1', '162_kb1', '117_kb1', '148_kb1', '181_kb1', '110_kb1', '123_kb1', '70_kb1', '160_kb1', '29_kb1', '142_kb2', '78_kb2', '17_kb2', '63_kb2', '113_kb2', '133_kb2', '26_kb2', '160_kb2', '179_kb2', '149_kb2', '197_kb2', '86_kb2', '12_kb2', '13_kb2', '171_kb2', '148_kb2', '62_kb2', '49_kb2', '184_kb2', '30_kb2', '189_kb2', '102_kb2', '110_kb2']\n",
      "c0.Film:['108_kb1', '168_kb1', '50_kb1', '130_kb1', '83_kb1', '135_kb1', '190_kb1', '67_kb1', '58_kb1', '42_kb1', '61_kb1', '128_kb1', '23_kb1', '24_kb1', '166_kb1', '29_kb1', '1_kb1', '95_kb1', '118_kb1', '145_kb1', '114_kb1', '46_kb1', '181_kb1', '92_kb1', '137_kb1', '27_kb1', '118_kb2', '92_kb2', '1_kb2', '168_kb2', '24_kb2', '95_kb2', '114_kb2', '125_kb2', '46_kb2', '27_kb2', '138_kb2', '108_kb2', '199_kb2', '83_kb2', '62_kb2', '166_kb2', '151_kb2', '61_kb2', '98_kb2', '58_kb2', '137_kb2']\n",
      "c0.Group:['180_kb1', '29_kb1', '168_kb1', '61_kb1', '61_kb2', '168_kb2', '180_kb2']\n",
      "c2.ES:['9_kb1', '126_kb1', '180_kb1', '29_kb1', '97_kb1', '97_kb2']\n",
      "c2.FR:['75_kb1', '46_kb1', '106_kb1', '126_kb1', '24_kb1', '52_kb1', '139_kb1', '83_kb1', '29_kb1', '136_kb1', '97_kb1', '24_kb2', '30_kb2', '197_kb2', '98_kb2', '46_kb2', '136_kb2', '83_kb2', '97_kb2']\n",
      "c2.IT:['75_kb1', '61_kb1', '121_kb1', '83_kb1', '29_kb1', '136_kb1', '138_kb2', '61_kb2', '121_kb2', '60_kb2', '113_kb2', '136_kb2']\n",
      "c0.For:['29_kb1', '144_kb2']\n",
      "c0.Love:['95_kb1', '29_kb1', '181_kb1', '95_kb2', '113_kb2']\n",
      "c0.and:['191_kb1', '133_kb1', '106_kb1', '108_kb1', '105_kb1', '130_kb1', '93_kb1', '147_kb1', '29_kb1', '93_kb2', '108_kb2']\n"
     ]
    }
   ],
   "source": [
    "for i, block in enumerate(attribute_blocks):\n",
    "    # Print 10 blocks for example\n",
    "    if i < 10:\n",
    "        print(\"{}:{}\".format(block, attribute_blocks[block]))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad4f2b",
   "metadata": {},
   "source": [
    "# Meta-Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b84f83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entity_index(blocks, entities):\n",
    "    entity_index = {}\n",
    "    for entity in entities:\n",
    "        entity_index[entity] = []\n",
    "    for key, value in blocks.items():\n",
    "        for entity in value:\n",
    "            entity_index[entity].append(key)\n",
    "    return entity_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f855764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllEntities(kb, kb_name):\n",
    "    entities = [str(idxRow) + kb_name for idxRow, row_ in kb.iterrows()]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad5f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = getAllEntities(test_db1, '_kb1')\n",
    "all_entities.extend(getAllEntities(test_db2, '_kb2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51108941",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_index_token_blocks = create_entity_index(token_blocks, all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10f5d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_index_attribute_blocks = create_entity_index(attribute_blocks, all_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7020d07",
   "metadata": {},
   "source": [
    "## Jaccard scheme and the common blocks scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec5e4e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scheme(blocks_i, entity_i, blocks_j, entity_j, type_of_scheme=\"Common\"):\n",
    "    inter_blocks_ij = []\n",
    "    for block in blocks_i:\n",
    "        if entity_j in block and entity_i in block:\n",
    "            inter_blocks_ij.append(block)\n",
    "    if type_of_scheme == \"Jaccard\":\n",
    "        return len(inter_blocks_ij) / (len(blocks_i) + len(blocks_j) - len(inter_blocks_ij))\n",
    "    return len(inter_blocks_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d929dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(blocks, entity_index, type_of_scheme=\"Jaccard\"):\n",
    "    E = []\n",
    "    V = set()\n",
    "    W = []\n",
    "    for block in blocks:\n",
    "        ps_1 = [p for p in blocks[block] if p[-3:] == \"kb1\"]\n",
    "        ps_2 = [p for p in blocks[block] if p[-3:] == \"kb2\"]\n",
    "        for p1 in ps_1:\n",
    "            V.add(p1)\n",
    "            for p2 in ps_2:\n",
    "                V.add(p2)\n",
    "                blocks_1_id = entity_index[p1]\n",
    "                blocks_2_id = entity_index[p2]\n",
    "                blocks_1 = [blocks[id1] for id1 in blocks_1_id]\n",
    "                blocks_2 = [blocks[id2] for id2 in blocks_2_id]\n",
    "                weight = Scheme(blocks_1, p1, blocks_2, p2, type_of_scheme)\n",
    "                E.append((p1,p2))\n",
    "                W.append(weight)            \n",
    "    norm_W = [(float(i)-min(W))/(max(W)-min(W)) for i in W]\n",
    "    return V, E, norm_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb9ff720",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_token_jaccard = make_graph(token_blocks, entity_index_token_blocks)\n",
    "graph_attribute_jaccard = make_graph(attribute_blocks, entity_index_attribute_blocks)\n",
    "graph_token_common = make_graph(token_blocks, entity_index_token_blocks, type_of_scheme=\"Common\")\n",
    "graph_attribute_common = make_graph(attribute_blocks, entity_index_attribute_blocks, type_of_scheme=\"Common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3e2d2",
   "metadata": {},
   "source": [
    "## Weight edge pruning and the cardinality node pruning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b4fb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WEP(graph):\n",
    "    V = graph[0]\n",
    "    E = graph[1]\n",
    "    W = graph[2]\n",
    "    W_min = np.mean(W)\n",
    "    low_W_index = []\n",
    "    for i in range(0,len(E)):\n",
    "        if W[i] < W_min:\n",
    "            low_W_index.append(i)\n",
    "    E = np.delete(E, low_W_index, axis=0)       \n",
    "    W = np.delete(W, low_W_index)\n",
    "    return V, E, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40df147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CEP(graph, K):\n",
    "    V = graph[0]\n",
    "    E = graph[1]\n",
    "    W = graph[2]\n",
    "    sorted_stack = {}\n",
    "    for i in range(0,len(E)):\n",
    "        sorted_stack[i] = W[i]\n",
    "        sorted_stack = {k: v for k, v in sorted(sorted_stack.items(), key=lambda item: item[1], reverse=True)}\n",
    "        \n",
    "        if K < len(sorted_stack):\n",
    "            sorted_stack.popitem()\n",
    "    retain_index = sorted_stack.keys()\n",
    "\n",
    "    E = [E[i] for i in retain_index] \n",
    "    W = [W[i] for i in retain_index] \n",
    "    return V, E, W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981416db",
   "metadata": {},
   "source": [
    "## Meta-blocking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eeade36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocking_cardinality(blocks, entities_size):\n",
    "    output = 0\n",
    "    for block in blocks:\n",
    "        output = output + len(block)\n",
    "    return output / entities_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eb327ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_token = math.floor(blocking_cardinality(token_blocks.values(), \n",
    "                                          len(all_entities))*len(all_entities))/2\n",
    "\n",
    "graph_token_jaccard_WEP = WEP(graph_token_jaccard)\n",
    "graph_token_jaccard_CEP = CEP(graph_token_jaccard, K_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffdd6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_attribute = math.floor(blocking_cardinality(attribute_blocks.values(), \n",
    "                                              len(all_entities))*len(all_entities))/2\n",
    "\n",
    "graph_attribute_jaccard_WEP = WEP(graph_attribute_jaccard)\n",
    "graph_attribute_jaccard_CEP = CEP(graph_attribute_jaccard, K_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cd6bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_token_common_WEP = WEP(graph_token_common)\n",
    "graph_token_common_CEP = CEP(graph_token_common, K_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3c3deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_attribute_common_WEP = WEP(graph_attribute_common)\n",
    "graph_attribute_common_CEP = CEP(graph_attribute_common, K_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07110be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 (oliverton)",
   "language": "python",
   "name": "oliverton"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
